---
title: 支持向量机
createTime: 2025/02/14 13:37:55
permalink: /open/ml/svm.md
---

## 支持向量机是什么

支持向量机（Support Vector Machine，SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。

## 支持向量机的原理

### 间隔与支持向量

给定线性可分训练数据集，通过间隔最大化，求得的分离超平面为

$$ w^* \cdot x + b^* = 0 $$ 

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

## 学习的对偶算法

### 学习的对偶算法

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

### 学习的对偶算法

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

## 核函数

### 核技巧

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

### 核函数

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

# 支持向量机的推广

## 类别不平衡问题

### 类别不平衡问题

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

### 类别不平衡问题

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数

$$ f(x) = sign(w^* \cdot x + b^*) $$

这里，$w^*$ 和 $b^*$ 是通过训练数据集学习得到的参数，$w$ 是权值向量，$b$ 是偏置，$x$ 是输入特征向量。

## 软间隔与正则化  

### 软间隔与正则化

给定线性可分训练数据集，通过求解凸二次规划问题学习得到的分离超平面为

$$ w^* \cdot x + b^* = 0 $$

以及相应的分类决策函数
